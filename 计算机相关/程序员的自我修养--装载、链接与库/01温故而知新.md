# 计算机系统
## 1.2 万变不离其宗
**硬件结构的演变**
1. 3个核心部件：cpu & 内存 & I/O控制芯片的基本结构。
2. Bus 总线
    + cpu频率提升，内存跟不上，产生了跟内存频率一致的系统总线，cpu采用倍频方式和总线通信。
3. Northbridge，PCI Bridge
    + 图形设备普及，GPU的快速发展，使得GPU、CPU和内存之间存在大量的数据交换。人们设计了北桥芯片，以便他们之间可以高速的交换数据。
    + 连接几个高速设备，包括内存和PCI总线
4. Southbridge ISA Bridge 
    + 所有低速设备连接到南桥上，然后由南桥汇总到北桥。（南桥芯片 连接低速设备 “磁盘、USB、键盘、鼠标等”）
    + ISA总线 ISA BUS 连接低速设备。
5. 万变不离其宗
    + 基本结构仍然是CPU+内存+I/O

**SMP和多核**


受限于CPU制造工艺，CPU频率的提升达到瓶颈，开始通过提升CPU数量来提升运算性能。

+ “对称多处理器（SMP，Symmetrical Multi-Processing”
    + 多个处理器

+ “多核处理器（Multi-core Processor”
    + 处于成本考虑，多个处理打包成一个处理器，多核共享昂贵的缓存部件。

## 1.3 站得高，望的远
**软件体系的层次结构**
计算机系统软件体系结构采用一种层的结构。计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。
层之间通讯必须有一个通讯协议称之为接口。下层是接口的提供者，由它定义接口。上层是接口的使用者，使用接口功能。
理论上只要层次之间只要遵循接口任何层次都可以被替换。这方便实现硬件和操作系统的向后兼容。虚拟机技术就是增加了一个虚拟层。

+ 应用程序和开发工具层
    + 使用操作系统应用程序编程接口（Application Programming Interface）。接口的提供者是运行时库。Linux下的Glibc的POSIX的API，windows下的Windows API。

+ 运行时库层 runtime Library
    + 使用系统操作系统提供的系统调用接口（System call interface）。系统调用接口在实现中往往以软件中断（Software Interrupt）。Linux用0x80号中断作为系统调用接口，Windows使用0x2E号中断作为系统调用接口。

+ 系统内核层 Operating System kernel
    + 是硬件层的硬件接口的使用者。

+ 硬件层 Hardware
    + 硬件接口往往称为硬件规格（Hardware Specification）。硬件厂商提供规格，系统和驱动程序开发者按照规格开发操作系统和驱动程序。

## 1.4 操作系统做什么
+ 提供抽象接口
+ 管理硬件资源
    + 硬件资源有限，充分发挥硬件潜能。

### 1.4.1  不要让CPU打盹

**cpu调度的演进**
+ 多道程序（Mutiprogarmming）
    + 监控程序监控CPU，当某个程序不适用CPU时，把在等待CPU资源的程序启动。比较原始，调度策略粗糙，没有轻重缓急。
+ 分时系统（Time-Sharing System）
    + 稍微演进，监控程序更加复杂。
    + 协作模式，每个程序运行一段时间后都主动让出CPU给其他程序。这对一些交互式的任务尤为重要。wind95和win NT之前，Mac OS X之前都采用这种分时系统。
    + 存在问题：如果一个程序进行耗时计算，一直霸着CPU不放，其他程序必须等着，整个系统看着像进入死机状态。如while（1）。
+ 多任务系统 （Muti-tasking）
    + 操作系统接管所有硬件资源。
    + 操作系统运行在一个受硬件保护的级别，应用程序以进程process的方式运行在比操作系统更低权限的级别。
    + 进程独立地址空间，地址空间隔离。
    + cpu由操作系统统一调度，根据进程优先级都有机会得到cpu，但运行超出一定时间，系统会暂停该程序，将cpu分配给等待的进程。
    + 这种CPU的分配方式是抢占式（Preemptive）。操作系统可以剥夺CPU资源并分配给它认为目前最需要的进程。

### 1.4.2 设备驱动

操作系统作为硬件的上层，它是对硬件的管理和抽象。
成熟的操作系统，硬件被抽象成一系列概念。避免程序编写者对纷杂硬件的直接操作（端口、操作方式、访问方式不一）。

+ UNIX系统，硬件设备的访问跟普通文件的访问一样。
+ windows系统中，图形硬件被抽象成了GDI，声音和多媒体被抽象成了DirectX对象，磁盘被抽象成了普通文件系统。

繁琐的硬件细节交给操作系统，具体是交给硬件驱动（Device Driver）程序。驱动程序运行在和操作系统内核一样的特权级，并保留独立性，更灵活适配。
操作系统开发者为硬件生产厂商提供了一系列接口和框架，凡是按照这个接口和框架开发的驱动程序都可以在该操作系统上使用。

**文件读取**

从文件读取看系统访问设备的过程。

扇区&盘片&磁道。

摒弃硬件细节，抽象为LBA （Logical block Adress）。给出一个逻辑扇区号，硬盘的电子设备将它转换为实际盘面、磁道等位置。

文件系统将文件写入磁盘，保存了这些文件的存储结构，负责维护这些数据结构并保证磁盘中的扇区能够有效的组织和利用。

假如：读取文件的前4096字节位于磁盘的1000-1007号逻辑扇区。
+ read系统调用
+ 文件系统收到read请求并向磁盘驱动发出一个从1000开始8个扇区的请求。
+ 驱动向硬盘发出硬件指令。
    + 硬件的I/O命令有很多种，最常见的一种是通过I/O端口寄存器。
    + x86平台有65536个硬件端口寄存器，不同的硬件被分配不同的I/O端口。
    + CPU提供给了俩条指令in 和 out 来对硬件端口读写。
    + IDE接口有俩个通道，IDE0和IDE1，分别为Master和Slave，一个PC最多可以有四个IDE。
    + IDE0通道的I/O端口地址是0x1F0～0x1F7及0x376～0x377。通过读写这些端口地址就能与IDE硬盘进行通信。
    + 第0x1F3～0x1F6 4个字节的端口地址是用来写入LBA地址的，那么1000号逻辑扇区的LBA地址为0x000003E8，所以我们需要往0x1F3、0x1F4写入0x00，往0x1F5写入0x03，往0x1F6写入0xE8。
    + 0x1F2 写入扇区数 8
    + 0x1F7这个地址用来写入要执行的操作的命令码，对于读取操作来说，命令字为0x20。
+ 硬盘收到这个命令后，就会执行相应操作，并将数据读取到事先设置好的内存中。

##  1.5 内存不够用怎么办？

早期程序直接访问物理的地址的弊端
+ 安全性，地址不隔离，恶意程序可以修改其他程序的数据。
+ 效率，有限的内存空间可能导致大量的数据换入换出。
+ 编写程序麻烦，每次载入内存的地址不固定，访问数据和指令跳转的目标地址需要重定位。

方案：
增加中间层，间接地址访问，虚拟地址（virtual address）。
### 1.5.1 关于隔离

程序不希望介入复杂的存储器管理。需要一个执行环境，一个地址空间，一个CPU，好像这个程序占用整个计算机而不关系其他程序。

个人感觉这里也可以是面向抽象的一种体现，把物理地址抽象为虚拟地址，简单认为整个内存地址都可以被我使用，摒弃复杂物理地址管理。

虚拟地址空间由cpu位数决定，跟实际的物理地址空间不符。

每个进程都有自己的虚拟地址空间，且只能访问自己的地址空间，这样就有效的实现地址隔离。

### 1.5.2 分段 Segmentation

把程序所需大小的虚拟地址映射到某个地址空间。可以解决地址隔离和地址不确定问题。换入换出粒度大，效率仍然不高，对内存管理需要更细的粒度，提高内存的使用效率。

### 1.5.3 分页 Paging
把地址空间分成固定大小的页，每一页大小由硬件决定，硬件支持多种大小，由操作系统决定。

+ 局部性原理 
    + 把进程的虚拟地址空间按页分割，把常用的代码页和数据装载到内存中，不常用的在磁盘，用到时从磁盘读取。
+ page fault 
    + 用到的页不在内存中，触发page fault，然后操作系统接管进程，负责将所需页装入内存，并将物理页和虚拟页建立映射关系。
+ 安全
    + 保护也是页映射目的之一，简单说每个页可以设置权限属性，谁可以修改，谁可以访问等等，而只有操作系统有权限修改这些属性，那么操作系统就可以做到保护自己和保护进程。
+ MMU Memory Management Unit
    + 虚拟存储的实现需要硬件支持，在页映射模式下，cpu看到的是Virtual Address，即我们程序看到的是虚拟地址，经过MMU的转换以后就变成了Physical Address。一般MMU都及成果在CPU内部了，，不会以单独部件存在。

## 众人拾柴火焰高之多线程

### 1.6.1 线程基础

现代软件系统中，进程和线程都是十分重要的概念。

特别是随着CPU频率增长停滞，开始向多核发展。多线程作为实现软件并发的一个重要方法，地位越来越重要。

**什么是线程**

+ Thread有时被称为轻量级进程 Lightweight Process LWP,是程序执行流的最小单元。
+ 一个标准的线程由线程ID、当前指令指针（PC）、寄存器集合、和堆栈组成。
+ 通常意义上一个集成由多个线程组成，各个线程之间共享内存空间（包括代码段、数据段、堆等）及一些进程级资源（如打开文件和信号）。

**线程的好处**

+ 有效利用等待时间，有效利用CPU多核
+ 异步执行耗时操作，不阻断交互

**线程的访问权限**
可以访问进程中所有数据，包括其他线程的堆栈（如果他知道其他线程的堆栈地址，少见），实际运用中线程拥有自己的私有存储空间。
+ 栈 一般认为私有，虽然并非完全无法被其他线程访问
+ 线程局部存储 TLS Thread Location Storage，操作系统为线程提供的私有空间，通常只具有限的容量。
+ 寄存器 包括PC寄存器，寄存器是执行流的基本数据，因此为线程私有。

**线程调度与优先级**

线程小于处理器数量时是真正的并发，在不同处理器上互不干扰。
单处理器是模拟出来的状态。操作系统会让这些多线程程序轮流执行，每次仅执行一小段时间（通常几十到几百毫秒），这样每个线程就看起来同时执行。

这样一个不断在处理器上切换不同的线程的行为称之为线程调度（Thread Shedule）。

+ 运行（Runing） 线程在执行
+ 就绪 ready 线程可以立即执行，但cpu被占用
+ 等待 waiting 此时线程正在等待某一件事（通常是I/O或同步）发生过

状态轮转
+ runing to ready
    + 每个线程都拥有一段执行时间称之为时间片 Time Slice，当时间片用尽进入就绪ready。
+ runing to waiting
    + 如果在时间片用尽之前就开始等待某件事，那么他将进入等待waiting状态。
+ ready to runing
    + 每当一个个线程离开运行状态，调度系统就会选择一个其他的就绪线程执行。
+ waiting to ready
    + 等待事件发生之后，等待结束。

线程调度自多任务系统问世以来就被不断提出不同的方案和算法。尽管调度方式不尽相同，但都有以下俩个算法痕迹。
+ 优先级调度 Priority Schedule
+ 轮转法 Round Robin

线程优先级该改变的三种方式

+ 用户指定 （实际需要）
+ 根据进入等待的频繁程度提升和降低优先级（频繁进入等待的I/O密集型更容易获得优先级提升，CPU密集型相反）
+ 长时间得不到执行的线程会被提升优先级（防止饿死）
**可抢占线程和不可抢占线程**
+ 不可抢占线程：主动放弃时间片 或者 等待某事件（I/O等）
+ 可抢占线程：时间片用尽 或者 等待某事件（I/O等）
尽管不可抢占线程调度端的时机是确定的，可以避免抢占式线程里调度实际不确定的问题，但是现代操作系统中非抢占式操作系统已经十分少见。

**Linux的多线程**
window系统里有明确的线程和进程概念。
linux系统中都是任务，类似单线程的进程。
+ 早期的Linux系统是通过LinuxThread模拟线程来实现多线程的，对POSIX标准的兼容性不好。
    + 创建线程，PID不一致
    + 同步互斥，通过信号模拟，效率不高，影响原有进程的信号处理。
    + 信号处理  只有拥有对应PID的进程才能处理
    + 线程管理  创建一个线程，会自动创建一个管理线程，线程的创建终止都需要这个管理线程（毕竟对内核来说都是进程）。
+ 2.6之后，通过NPTL来实现多线程，增强了对多线程的支持
    + 内核的进程管理结构新增了TGID（Thread Group ID）字段。主线程的PID即子线程的TGID，子线程有各自的PID，调用getPid返回TGID。TGID相同则为一个线程组。内核通过新增字段TGID就可以识别进程和线程。
    + 同步互斥，增加一个新的互斥同步原语futex(fast usespace locking system call)，意为快速用户空间系统锁，这个锁在用户空间，操作不需要切到内核态，大大加快了存取速度。NPTL的同步互斥机制都是建立在futex上的。
    + 信号处理，同一进程的线程被标记为同一线程组TGID，所以信号处理跟POSIX标准完全统一。发送一个SIGSTP号，进程中所有线程都会停止。
    + 线程管理，统一由系统内核处理

fork() 创建新进程，仅仅复制了父进程页表() COW copy on write 写时赋值。
exec和fork配合使用,用来开启新任务，加载新可执行文件。
clone 创建新线程 fork的升级版，可以指定新的命名空间（name space），有选择的继承父进程的内存、甚至可以将创建出来的进程变成父进程的兄弟进程。

### 1.6.2 线程安全

**竞争和原子操作**
cpu的单指令操作成为原子操作 atomic。
例如：i++ 三个单指令操作，读取到寄存器，计算，写回。
不同的操作系统都会提供一套API来专门进行一些院子操作，如windows的inc指令可以atomic的增加一个内存单元值。

缺点：
    仅适用于比较简单特定的场合。为保证复杂数据结构更改的原子性，我们需要更加通用的手段：锁。

**同步与锁**
+ 二元信号量 占用和非占用。
+ 多元信号量
+ 互斥量 与二元信号量的区别是，整个系统只有获得锁的线程才可以释放锁，其他线程释放是无效的。
+ 临界区 比互斥锁更严格的同步手段，作用只限于本进程。二元和互斥量，是可以被其他进程获取的。
+ 读写锁 特定场合同步。 shared 和 Exlusive 俩种获取方式，读时shared获取，可以和其他读取操作共享。写实Exlusive获取，需等待说有shared获取的或者Exlusive获取的线程释放。
+ 条件变量 （Condition Variable）作为一种同步手段。

**可重入函数与线程安全**
+ 不使用任何静态或全局的非const变量。
+ 不返回任何惊天或全局的非const变量的指针。
+ 进依赖于调用方提供的参数。
+ 不依赖任何单个资源的锁。
+ 不调用任何不可重入的函数。

可以重入是并发安全的强力保障，可以在多线程环境下放心使用。

**过度优化**
+ 编译期优化
1.寄存器延迟写回提高访问效率
2.调整指令执行顺序

例子：
x = 0；
Thread1 Lock(); x++; unlock();
Thread2 Lock(); x++; unlock();

编译器为了提高x的发给速度，把x放到某个寄存器中，延迟写回，可以导致结果非预期。

+ cpu动态调度
1.调整指令执行顺序

例子：
x=y=0；
Thread1  x=1; r1 = y;
Thread2  y=1; r2 = x;

r1和r2逻辑上不可能同时为0，实际上可以。
因为俩行代码 x=1，r1 = y，毫无因果关系,cpu在实际执行顺序可能为了提高效率交换指令的顺序，先执行r1=y.
同样，编译器在进行优化的时候，也可能为了效率而交换毫不相干的两条相邻指令（如x=1和r1=y）的执行顺序.
r1和r2可能同时为0.

解决方法：

+ volatitle 关键字
阻止编译器为了提高速度讲一个变量缓存到寄存器内而写回。
阻止编译器调整volatitle变量的执行顺序。

volatitle解决了编译器的优化问题，并不能阻止cpu的动态调度。

+ barrier指令

“volatile T* pInst = 0;
T* GetInstance()
{
if (pInst == NULL)
{
    lock();
    if (pInst == NULL)
        pInst = new T;
    unlock();
}
return pInst;
}”

以上看似没有问题的代码，依然存在问题。 
 pInst = new T包含三步。
 1.申请内存空间 2.在内存位置调用构造函数 3.内存地址赋值给pInst。

实际执行中3可能2之前，如果某个线程在外层的pInst == NULL获取到了没有完成初始化的内存，可能会访问导致奔溃。

barrirer指令可以阻止cpu将barrier前后的指令交换。

“{
    if (!pInst)
    {
        lock();
        if (!pInst)
        {
            T* temp = new T;
            barrier();
            pInst = temp;
        }
        unlock();
    }
    return pInst;
}”

如此即保证了单例对象的唯一，也避免了单例对象在使用时未初始化完成。

### 1.6.3 线程模型
内核线程 由多处理器或调度来实现并发。
用户态线程  用户实际使用并不是内核线程而是用用户态线程。如某个轻量级线程库，对用户来说如果有三个线程在同时执行，对内核来说可能只有一个。

+ 一对一模型 
    用户线程和内核线程一致。
    优点： 真正的并发，一个线程阻塞，其他线程不收影响。
    缺点： 很多系统内核线程数量有限，一对一线程让用户线程数量受限。很多系统内核线程调度时，上下文切换开销比较大，导致用户态线程执行效率低。
+ 多对一模型
    多个用户线程对应一个内核线程。
    优点：用户态线程切换快速。无限制的用户态线程数量。
    缺点：一个用户态线程阻塞，内核线程阻塞，其他用户态线程阻塞。
+ 多对多模型
    优点：一个用户线程阻塞，还以有别的线程来调度。无限制的用户态线程数量。

## 小结
“在这一章中，我们对整个计算机的软硬件基本结构进行了回顾，包括CPU与外围部件的连接方式、SMP与多核、软硬件层次体系结构、如何充分利用CPU及与系统软件十分相关的设备驱动、操作系统、虚拟空间、物理空间、页映射和线程的基础概念。虽然这些概念都是大家所了解的，但是我们认为还是有必要回顾一下，它们跟本书后面章节介绍的内容息息相关。正所谓温故而知新，这就是本章的目的。”



























